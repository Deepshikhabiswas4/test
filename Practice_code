def main(spark):
    today_oracle_fmt = datetime.today().strftime("%d-%m-%Y")

    run_id = get_run_id(spark, today_oracle_fmt)

    logger = create_logger(run_id)

    logger.info("===================================")
    logger.info("CBS BALANCE JOB STARTED")
    logger.info(f"Run ID: {run_id}")
    logger.info("===================================")

    try:
        logger.info("Reading data from Oracle")
        # oracle read logic

        logger.info("Writing to Delta Lake")
        # delta write logic

        logger.info("Job completed successfully")

    except Exception as e:
        logger.error("Job failed", exc_info=True)
        raise

    finally:
        logger.info("CBS BALANCE JOB ENDED")

