import sys
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, to_date, lit
from datetime import date

def main():
    # HDFS table path
    HDFS_PATH = "hdfs://10.177.103.199:8022/data-lake/Fincore/Gl_Balance"

    # Business date
    today = "2025-12-02"

    try:
        # Spark session with Delta support
        spark = SparkSession.builder \
            .appName("GL Balance Mismatch Check") \
            .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
            .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
            .getOrCreate()

        print(f"Reading Delta Lake data from: {HDFS_PATH}")
        df_delta = spark.read.format("delta").load(HDFS_PATH)

        # Filter Delta data for today's records
        df_today_delta = df_delta.filter(to_date(col("BALANCE_DATE")) == to_date(lit(today))) \
                                 .select("GLCC", col("closing_balance").alias("delta_balance"))

        print("Delta Table Sample Data:")
        df_today_delta.show(20, False)

        # Read from Oracle database
        jdbc_url = "jdbc:oracle:thin:@//<HOST>:<PORT>/<SERVICE>"
        db_properties = {
            "user": "<USERNAME>",
            "password": "<PASSWORD>",
            "driver": "oracle.jdbc.driver.OracleDriver"
        }

        print("Reading today's balance from Oracle database...")
        query = f"(SELECT GLCC, CLOSING_BALANCE FROM GL_BALANCE WHERE BALANCE_DATE = DATE '{today}') alias"
        df_oracle = spark.read.jdbc(url=jdbc_url, table=query, properties=db_properties) \
                           .select("GLCC", col("CLOSING_BALANCE").alias("db_balance"))

        print("Oracle Database Sample Data:")
        df_oracle.show(20, False)

        # Compare both datasets
        comparison_df = df_today_delta.join(df_oracle, on="GLCC", how="fullouter") \
                                      .withColumn("difference", col("delta_balance") - col("db_balance"))

        print("\n========= MISMATCH RECORDS =========")
        mismatch_df = comparison_df.filter(col("difference") != 0)
        mismatch_df.show(50, False)

        print("\n========= SUMMARY =========")
        print("Total Delta records: ", df_today_delta.count())
        print("Total DB records: ", df_oracle.count())
        print("Mismatch count: ", mismatch_df.count())

    except Exception as e:
        print(f"Error validating GL Balance: {e}")
        sys.exit(1)

    finally:
        if 'spark' in locals():
            spark.stop()

if __name__ == "__main__":
    main()
