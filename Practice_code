from pyspark.sql import SparkSession
import sys

def main():

    spark = SparkSession.builder \
        .appName("HDFS_Read_Verification") \
        .getOrCreate()

    # Path will be given by your mentor
    input_path = sys.argv[1]

    print(f"Trying to read files from path: {input_path}")

    try:
        # Step 1: Read files from HDFS
        df = spark.read \
            .option("header", "true") \
            .option("inferSchema", "true") \
            .csv(input_path)

        # Step 2: Trigger action (important!)
        record_count = df.count()

        print("✅ SUCCESS")
        print(f"Total records read: {record_count}")

        # Step 3: Show sample records
        df.show(5, truncate=False)

    except Exception as e:
        print("❌ FAILED TO READ FILES")
        print(str(e))
        sys.exit(1)

    spark.stop()

if __name__ == "__main__":
    main()

