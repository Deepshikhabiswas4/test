from pyspark.sql import SparkSession

# 1️⃣ Start fresh Spark session
spark = (
    SparkSession.builder
    .appName("csv-write-test")
    .getOrCreate()
)

# 2️⃣ Create a tiny DataFrame
data = [
    (1, "Alice", 100.50),
    (2, "Bob", 200.75),
    (3, "Charlie", 300.00)
]

columns = ["id", "name", "amount"]

df = spark.createDataFrame(data, columns)

# 3️⃣ Print DF (driver side)
df.show(truncate=False)

# 4️⃣ CSV write path (KEEP IT SIMPLE)
test_path = "hdfs://10.177.103.199:8022/data-lake/Fincore/spark_cluster/csv_test_simple"

print("WRITING CSV TO =>", test_path)

# 5️⃣ Write CSV
(
    df
    .coalesce(1)        # one CSV file for easy checking
    .write
    .format("csv")
    .option("header", "true")
    .mode("overwrite")
    .save(test_path)
)

print("CSV WRITE SUCCESS")

# 6️⃣ Stop Spark
spark.stop()
