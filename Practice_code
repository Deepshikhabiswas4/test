import sys
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, to_date, lit, sum as _sum

def main():
    HDFS_PATH = "hdfs://10.177.103.199:8022/data-lake/Fincore/CBS_balance"

    try:
        spark = SparkSession.builder \
            .appName("CBS Balance Today Calculation") \
            .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
            .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
            .getOrCreate()

        # Business date
        today = "2025-12-02"

        # Read delta table
        df = spark.read.format("delta").load(HDFS_PATH)

        # Filter for today's records only
        df_today = df.filter(to_date(col("BALANCE_DATE")) == to_date(lit(today)))

        # Calculate sum per GLCC
        df_grouped = df_today.groupBy("GLCC") \
                             .agg(_sum("closing_balance").alias("today_total_balance"))

        print("================ Today's Balance by GLCC ================")
        df_grouped.show(100, False)

        # Calculate total combined balance for today
        total_balance = df_grouped.agg(_sum("today_total_balance")).collect()[0][0]
        print(f"\n================ Total Balance for Today ({today}) ================")
        print(total_balance)

    except Exception as e:
        print(f"Error calculating today's balance: {e}")
        sys.exit(1)
    finally:
        if 'spark' in locals():
            spark.stop()

if __name__ == "__main__":
    main()
