from pyspark.sql import functions as F
from pyspark.sql.types import DecimalType, IntegerType, LongType, StringType


def process_single_file_dynamic(
    spark,
    etl_date,
    run_id,
    file_path,
    file_name
):
    """
    Reads ONE CBS / GLIF file, dynamically parses it using DB metadata,
    and returns the final dataframe (BUSINESS COLUMNS ONLY).
    """

    # ---------------------------------------------------------------
    # 1. Detect FILE TYPE from file name
    # ---------------------------------------------------------------
    file_name_upper = file_name.upper()

    if file_name_upper.startswith("GLIF"):
        file_type = "GLIF"

    elif file_name_upper.startswith("INV"):
        file_type = "INV"

    elif file_name_upper.startswith("BOR"):
        file_type = "BOR"

    elif file_name_upper.startswith("GLCCTA"):
        file_type = "GLCCTA"

    elif file_name_upper.startswith("GLCCGEN"):
        file_type = "GLCCGEN"

    else:
        raise Exception(f"Unsupported file type: {file_name}")

    # ---------------------------------------------------------------
    # 2. Read SINGLE raw file
    # ---------------------------------------------------------------
    raw_df = (
        spark.read.text(file_path)
        .withColumnRenamed("value", "RAW_RECORD")
    )

    # ---------------------------------------------------------------
    # 3. Read metadata dynamically from DB
    # ---------------------------------------------------------------
    metadata_df = (
        spark.table("FINCORE.TOTALDATAPARAMETERS")
        .filter(F.upper(F.col("FILE_TYPE")) == file_type)
        .filter(F.upper(F.col("TOBEINCLUDED")) == "Y")
        .select(
            F.upper(F.col("COLUMNNAME")).alias("COLUMNNAME"),
            F.col("STARTVALUE"),
            F.col("ENDVALUE"),
            F.upper(F.col("DATA_TYPE")).alias("DATA_TYPE")
        )
        .orderBy("STARTVALUE")
    )

    metadata = metadata_df.collect()

    if not metadata:
        raise Exception(f"No metadata found for FILE_TYPE = {file_type}")

    # ---------------------------------------------------------------
    # 4. Build substring expressions dynamically
    # ---------------------------------------------------------------
    select_exprs = []

    for row in metadata:
        col_name = row["COLUMNNAME"]
        start_pos = int(row["STARTVALUE"])
        end_pos = int(row["ENDVALUE"])
        data_type = row["DATA_TYPE"]

        length = end_pos - start_pos + 1
        base_col = F.substring(F.col("RAW_RECORD"), start_pos, length)

        if data_type in ("VARCHAR", "CHAR", "STRING"):
            final_col = base_col.cast(StringType())

        elif data_type in ("INT", "INTEGER"):
            final_col = base_col.cast(IntegerType())

        elif data_type in ("LONG", "BIGINT"):
            final_col = base_col.cast(LongType())

        elif data_type in ("DECIMAL", "NUMBER"):
            final_col = base_col.cast(DecimalType
