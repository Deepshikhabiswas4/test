from pyspark.sql import SparkSession
from pyspark.sql.functions import to_date, col, lit

oracle_url = "jdbc:oracle:thin:@//10.177.103.192:1523/fincorepdb1"
oracle_user = "fincore"
oracle_password = "Password#1234"
oracle_driver = "oracle.jdbc.driver.OracleDriver"

HDFS_BASE = "hdfs://10.177.103.199:8022"
CBS_BALANCE_DATALAKE_PATH_2 = f"{HDFS_BASE}/data-lake/Fincore/CBS_balance"

spark = SparkSession.builder.appName("Migrate_Oracle_2ndDec").getOrCreate()

df_dec2 = spark.read \
    .format("jdbc") \
    .option("url", oracle_url) \
    .option("dbtable", "CBS_BALANCE") \
    .option("user", oracle_user) \
    .option("password", oracle_password) \
    .option("driver", oracle_driver) \
    .load() \
    .filter(to_date(col("BALANCE_DATE")) == to_date(lit("2025-12-02")))

df_dec2.write \
    .format("delta") \
    .mode("append") \
    .save(CBS_BALANCE_DATALAKE_PATH_2)

spark.stop()
